{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60e7294-7dd5-4ef6-a1fd-d64e3849deee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from html.parser import HTMLParser\n",
    "import os\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc789436-a031-4b8e-a0f6-686a118fac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyHTMLParser(HTMLParser):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.list_content = []\n",
    "    \n",
    "    def handle_data(self, data):\n",
    "        if \"window.__REACT_DATA = \" in data:\n",
    "            content = data.split(\"window.__REACT_DATA = \")[1][:-2] # removing the last ';'\n",
    "            dict_content = ast.literal_eval(content)\n",
    "            self.list_content += [dict_content]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50293c95-df46-4fa7-a32e-2cbe5d237b4d",
   "metadata": {},
   "source": [
    "# You need to download html files from [here](https://hsk.academy/en/hsk-1-vocabulary-list)\n",
    "If the link does not work, copy this link: `https://hsk.academy/en/hsk-1-vocabulary-list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35ea611-46ae-4777-8b1e-0328db054dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"html_files/HSK_6.html\") as f:\n",
    "    html_file = \"\".join(f.readlines())\n",
    "\n",
    "parser = MyHTMLParser()\n",
    "parser.feed(html_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d67368-c0f0-4ed2-beb7-857588d99293",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_content = parser.list_content[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f256ec5-1ed4-46d4-bcae-25e79d41984c",
   "metadata": {},
   "source": [
    "# Structure of the content dictionnary\n",
    "\n",
    "### 1. Key `word`\n",
    "Contains a list of dictionnaries.\n",
    "Each dictionnary has 8 keys:\n",
    "\n",
    "`'id'`, `'hanzi'`, `'hanziRaw'`, `'trad'`, `'pinyinToneSpace'`, `'def'`, `'mp3File'`, `'oggFile'`\n",
    "\n",
    "Example of a dictionnary:\n",
    "```\n",
    "{'id': 684,\n",
    " 'hanzi': '得(助动词)',\n",
    " 'hanziRaw': '得',\n",
    " 'trad': '得(助動詞)',\n",
    " 'pinyinToneSpace': 'dé',\n",
    " 'def': 'devoir, pouvoir (particule utilisée pour exprimer la possibilité, la capacité, l’effet, le degré)',\n",
    " 'mp3File': '得(助动词).mp3',\n",
    " 'oggFile': '得(助动词).ogg'\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "- `id` contains just the number of the entry. **Useless**\n",
    "- `hanzi` contains the chinese character (simplified), with indication of auxiliary particules (助词) or verbs (助动词)\n",
    "- `hanziRaw` contains the chinese character whitout indication of auxiliary particules (助词) or verbs (助动词). **Useless**\n",
    "- `trad` contains the traditionnal hanzi. **Useless (for me)**\n",
    "- `pinyinToneSpace` contains the pinyin.\n",
    "- `def` contains the definition/translation\n",
    "- `mp3file` contains the name of the mp3 file with the audio of the word. **Useless**\n",
    "- `oggFile` contains the name of the ogg file with the audio of the word. **Useless**\n",
    "\n",
    "### 2. Key `wordIdToCharacters` (useless)\n",
    "Contains a dictionnary whose keys are the `id`s of every word, and the content are the decomposition of the world into different characters\n",
    "Example of `(key, value)` pairs:\n",
    "```\n",
    "'762': [{'slug': '果', 'hanzi': '果', 'wordId': 762},\n",
    "        {'slug': '汁', 'hanzi': '汁', 'wordId': 762}],\n",
    "'684': [{'slug': '得', 'hanzi': '得', 'wordId': 684}],\n",
    "```\n",
    "It seems that `slug` and `hanzi` values are always the same.\n",
    "\n",
    "### 3. Key `localizedSentences`\n",
    "Contains a list of dictionnaries. Each dictionnary has three keys: \n",
    "`'hanzi'`, `'pinyinTone'`, `'def'`\n",
    "Example:\n",
    "```\n",
    "{'hanzi': '你把火点着吧。',\n",
    " 'pinyinTone': 'Nǐ bǎ huǒ diǎnzhe ba.',\n",
    " 'def': 'Vous allumez le feu.'\n",
    "}\n",
    "```\n",
    "\n",
    "### 4. Key `hskLevel`\n",
    "The corresponding HSK level, i.e. `4` for instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bc9d8d-d690-404c-82ad-26326f6ab4f1",
   "metadata": {},
   "source": [
    "# Checking if there are special word entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd91a33-b1ee-437e-a564-d449796a645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dict_content[\"words\"]:\n",
    "    if d[\"hanzi\"] != d[\"hanziRaw\"]:\n",
    "        print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c751a6c7-40ec-4ed0-b334-6c53fc00fcbe",
   "metadata": {},
   "source": [
    "# Desired structure of the `.xml` file\n",
    "(two possible structure for a card):\n",
    "\n",
    "```\n",
    "<deck name=\"Chinois\">\n",
    "    <fields>\n",
    "        <chinese name='Chinois' sides='11' lang='zh-CN'  pinyinMode='hint'></chinese>\n",
    "        <text name='Traduction' sides='01' lang='fr-FR'></text>\n",
    "    </fields>\n",
    "    <cards>\n",
    "        <card>\n",
    "            <chinese name='Chinois'>月亮</chinese>\n",
    "            <text name='Traduction'>Lune</text>\n",
    "        </card>\n",
    "        <card>\n",
    "            <chinese name='Chinois'>\n",
    "                <chinese>介绍</chinese>\n",
    "            </chinese>\n",
    "            <text name='Traduction'>Introduire, présenter qqun </text>\n",
    "        </card>\n",
    "    </cards>\n",
    "</deck>\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a84ebd-f8a2-4bb5-83cf-bb97af04cd1a",
   "metadata": {},
   "source": [
    "## Creating words `.xml` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d78233-6f78-4e92-b4c9-4b39d8c8dd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "deck = ET.Element('deck', attrib={'name': f'HSK {dict_content[\"hskLevel\"]} Word List'})\n",
    "\n",
    "fields = ET.SubElement(deck, 'fields')\n",
    "chinese = ET.SubElement(fields, 'chinese', attrib={'name': 'Chinois', 'sides': '11', 'lang': 'zh-CN', 'pinyinMode': 'hint'})\n",
    "text = ET.SubElement(fields, 'text', attrib={'name': 'Traduction', 'sides': '01', 'lang': 'fr-FR'})\n",
    "\n",
    "cards = ET.SubElement(deck, \"cards\")\n",
    "ET.dump(deck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b971d3d-23a4-488c-9c8a-5e1af41103dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word_entry in dict_content[\"words\"]:\n",
    "    \n",
    "    hanzi = word_entry[\"hanzi\"]\n",
    "    definition = word_entry[\"def\"]\n",
    "    \n",
    "    # Replacing chinese grammar indicators\n",
    "    if hanzi != word_entry[\"hanziRaw\"]:\n",
    "        hanzi = hanzi.replace(\"(助动词)\", \"(verbe auxiliaire)\")\n",
    "        hanzi = hanzi.replace(\"(助词)\", \"(particule)\")\n",
    "        hanzi = hanzi.replace(\"(叹词)\", \"(interjection)\")\n",
    "        hanzi = hanzi.replace(\"(形容词)\", \"(adjectif)\")\n",
    "        hanzi = hanzi.replace(\"(介词)\", \"(préposition)\")\n",
    "        hanzi = hanzi.replace(\"(副词)\", \"(adverbe)\")\n",
    "        hanzi = hanzi.replace(\"(名词)\", \"(nom)\")\n",
    "        hanzi = hanzi.replace(\"(量词)\", \"(quantificateur)\")\n",
    "        \n",
    "    card = ET.SubElement(cards, \"card\")\n",
    "    chinese = ET.SubElement(card, 'chinese', attrib={'name': 'Chinois'})\n",
    "    chinese.text = hanzi\n",
    "    text = ET.SubElement(card, 'text', attrib={'name': 'Traduction'})\n",
    "    text.text = definition\n",
    "\n",
    "# For testing only\n",
    "# ET.dump(deck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea8bced-63ac-4f6f-b4c6-ca7532a231b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "deck_tree = ET.ElementTree(deck)\n",
    "deck_tree.write(f\"xml_outputs/HSK_{dict_content['hskLevel']}_word_list.xml\", encoding=\"unicode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15852793-7de2-4aaa-a78e-d7fbf76c8495",
   "metadata": {},
   "source": [
    "## Creating sentence `.xml` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfab8da0-c727-4ad9-8ac7-c092c4f68e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "deck = ET.Element('deck', attrib={'name': f'HSK {dict_content[\"hskLevel\"]} Sentence List'})\n",
    "\n",
    "fields = ET.SubElement(deck, 'fields')\n",
    "chinese = ET.SubElement(fields, 'chinese', attrib={'name': 'Chinois', 'sides': '11', 'lang': 'zh-CN', 'pinyinMode': 'hint'})\n",
    "text = ET.SubElement(fields, 'text', attrib={'name': 'Traduction', 'sides': '01', 'lang': 'fr-FR'})\n",
    "\n",
    "cards = ET.SubElement(deck, \"cards\")\n",
    "ET.dump(deck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54654fa0-90d8-46fb-8975-42a6f769c43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word_entry in dict_content[\"localizedSentences\"]:\n",
    "    \n",
    "    hanzi = word_entry[\"hanzi\"]\n",
    "    definition = word_entry[\"def\"]\n",
    "        \n",
    "    card = ET.SubElement(cards, \"card\")\n",
    "    chinese = ET.SubElement(card, 'chinese', attrib={'name': 'Chinois'})\n",
    "    chinese.text = hanzi\n",
    "    text = ET.SubElement(card, 'text', attrib={'name': 'Traduction'})\n",
    "    text.text = definition\n",
    "\n",
    "# For testing only\n",
    "# ET.dump(deck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd1af43-2111-4874-abb4-178c6a092516",
   "metadata": {},
   "outputs": [],
   "source": [
    "deck_tree = ET.ElementTree(deck)\n",
    "deck_tree.write(f\"xml_outputs/HSK_{dict_content['hskLevel']}_sentence_list.xml\", encoding=\"unicode\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
